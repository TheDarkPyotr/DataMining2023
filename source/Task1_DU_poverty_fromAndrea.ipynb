{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.1 - Data Understanding `povertyByState.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take a while\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import plotly.offline as py\n",
    "\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import the dataset\n",
    "# Poverty by state and year\n",
    "df_poverty = pd.read_csv('../source/ds/povertyByStateYear.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--\"*50)\n",
    "df_poverty.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First look at poverty dataset\n",
    "print(df_poverty.head())\n",
    "\n",
    "# Information about columns, data types, and presence of null values\n",
    "print(df_poverty.info())\n",
    "\n",
    "# Counting unique values for each column\n",
    "print(\"##########################################\")\n",
    "print(\"Counts unique values for each column\")\n",
    "print(df_poverty.nunique())\n",
    "\n",
    "print(\"##########################################\")\n",
    "print(\"List of all the values for the feature 'state'\")\n",
    "\n",
    "# Problem: there are 52 states\n",
    "unique_state_values = df_poverty['state'].unique()\n",
    "print(unique_state_values)\n",
    "print(\"##########################################\")\n",
    "\n",
    "# See the case where state = 'United States'\n",
    "# Select rows where 'state' is 'United States'\n",
    "print(\"Values for US\")\n",
    "df_united_states = df_poverty[df_poverty['state'] == 'United States']\n",
    "print(df_united_states)\n",
    "\n",
    "## Since I can't derive anything from it -> remove rows with United States for the State feature\n",
    "df_poverty_filtered = df_poverty[df_poverty['state'] != 'United States']\n",
    "print(\"##########################################\")\n",
    "print(\"Reprinting unique values for each column\")\n",
    "print(df_poverty_filtered.nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data types for this dataset are correct: object for the state is ok, int for the year column and foat for povertyPercebtae by definition.\n",
    "The initial datatset contains 52 states: for **District of Columbia** we decide to include it for the analysis but the value 'United states' can't be reshaped in a more fine grained value, so is dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value_year = df_poverty_filtered['year'].max()\n",
    "min_value_year = df_poverty_filtered['year'].min()\n",
    "print(f\"The range of the year for this dataset is {min_value_year};{max_value_year}\")\n",
    "\n",
    "max_value_perc = df_poverty_filtered['povertyPercentage'].max()\n",
    "min_value_perc = df_poverty_filtered['povertyPercentage'].min()\n",
    "print(f\"The range of the povertyPercentage for this dataset is {min_value_perc};{max_value_perc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see some info regarding missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting missing data for each column\n",
    "print(\"Missing values for each column:\")\n",
    "print(df_poverty_filtered.isnull().sum())\n",
    "\n",
    "## Displaying missing data\n",
    "column_missing_values = 'povertyPercentage'\n",
    "\n",
    "# Select rows with missing data in the specific column\n",
    "df_poverty_missing_povertyPercentage = df_poverty_filtered[df_poverty_filtered[column_missing_values].isnull()]\n",
    "\n",
    "# Print the selected rows\n",
    "print(df_poverty_missing_povertyPercentage)\n",
    "\n",
    "#### To manage the null data for 2012\n",
    "df_filt_pure = df_poverty_filtered\n",
    "df_filt_pureB = df_poverty_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate alternative poverty percentage based on filtered data and grouping by year\n",
    "alternative_poverty_percentage = df_poverty_filtered.groupby('year')['povertyPercentage'].mean()\n",
    "print(\"alternative poverty percentage\", alternative_poverty_percentage)\n",
    "\n",
    "# Calculate median poverty percentage excluding the year 2012\n",
    "median_poverty_percentage = df_poverty_filtered[df_poverty_filtered['year'] != 2012]['povertyPercentage'].median()\n",
    "\n",
    "# Weighted average using Gaussian distribution with weights favoring nearby years\n",
    "# Weights are assigned to years from 2004 to 2020, with a Gaussian distribution centered at 2012 but excluding 2012\n",
    "years_list = df_poverty_filtered['year'].unique()\n",
    "years_list = np.sort(years_list)\n",
    "\n",
    "sigma = 4\n",
    "# Compute Gaussian weights for each year based on their distance from 2012\n",
    "gaussian_weighting = np.exp(-np.square(years_list - 2012)/(2*sigma**2))\n",
    "\n",
    "# Remove the 12th value (2012) from the Gaussian weighting\n",
    "gaussian_weighting = np.delete(gaussian_weighting, 8)\n",
    "print(\"gaussian weighting\")\n",
    "print(gaussian_weighting)\n",
    "\n",
    "# Remove 2012 from alternative poverty percentage\n",
    "alternative_poverty_percentage = alternative_poverty_percentage.drop(2012)\n",
    "\n",
    "# Apply Gaussian weighting to the poverty percentage by multiplying each year's value with the corresponding weight,\n",
    "# then dividing by the sum of the weights\n",
    "expected_poverty_percentage = np.sum(alternative_poverty_percentage * gaussian_weighting) / np.sum(gaussian_weighting)\n",
    "print(\"expected poverty percentage \\n\", expected_poverty_percentage)\n",
    "\n",
    "# Replace missing values for the year 2012 with the calculated expected poverty percentage\n",
    "df_poverty_filtered.loc[df_poverty_filtered['year'] == 2012, 'povertyPercentage'] = expected_poverty_percentage\n",
    "print(\"Missing values for each column\")\n",
    "print(df_poverty_filtered.isnull().sum())\n",
    "\n",
    "# Filter the DataFrame for the year 2012\n",
    "df_pov2012 = df_poverty_filtered[df_poverty_filtered['year'] == 2012]\n",
    "print(df_pov2012.head()[['state', 'povertyPercentage']])\n",
    "\n",
    "# Assign the filtered DataFrame to a new variable for testing purposes\n",
    "df_prova = df_poverty_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spiegazione gaussian weighted method #todo\n",
    "In alterantiva, mostriamo il metodo semplice di sostituzione del valore con la mediana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################################### Calcola la mediana della poverty percentage escludendo il 2012\n",
    "poverty_fil_perc = df_filt_pure\n",
    "median_poverty_percentage = poverty_fil_perc[poverty_fil_perc['year'] != 2012]['povertyPercentage'].median()\n",
    "\n",
    "# Imputa i dati mancanti nel 2012 con la mediana calcolata\n",
    "poverty_fil_perc.loc[poverty_fil_perc['year'] == 2012, 'povertyPercentage'] = median_poverty_percentage\n",
    "\n",
    "# controllo se andato a buon fine:\n",
    "print(\"Missing values for each column\")\n",
    "print(poverty_fil_perc.isnull().sum())\n",
    "variabile_d_appoggio = poverty_fil_perc[df_poverty_filtered['year'] == 2012]\n",
    "\n",
    "# Stampa le percentuali di povertà per tutti gli stati nel 2012\n",
    "print(variabile_d_appoggio.head()[['state', 'povertyPercentage']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerations about povery percentage\n",
    "Given the nature of poverty percentage data type, can use the boxplot just to see if there are any outliers.\n",
    "To know the distribution we plot it using an histogram. \n",
    "\n",
    "As later shown, there are no outliers and respectively emerge that:\n",
    "- *State with highest peverty percentage*: New Mexico, 2013: 21.8\n",
    "- *State with lowest peverty percentage*: New Hampshire, 2018: 5.4\n",
    "\n",
    "It's important to highlight the distribution of mean (*poverty percentage*) for all the states with respect to the years we can do some considerations:\n",
    "    - Mean of poverty percentage increases starting from 2007/2008 until 2010\n",
    "    - The historical condition corresponds to a the real estate/finance bailout, leading to  an increse of unemployment so the mean increases\n",
    "    - from now on decreases until 2008 (exept for 2011->2012-2013) this is given by the fact that in thoose years USA's economy booted up\n",
    "    - The increase in 2011, the ***decrease*** in 2012 and the increase 2013 can be explained by the fact that we replaced 2012 NaN values, but we'll not make effort in reconstructing it because as our year range of interests start from $2013$, so we decided to drop the data prior to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize the distribution\n",
    "filtered_data = df_poverty_filtered['povertyPercentage']\n",
    "plt.boxplot(filtered_data, vert=True)  # vert=False makes it horizontal\n",
    "plt.xlabel('Age')\n",
    "plt.title('Boxplot of poverty percentage')\n",
    "plt.show()\n",
    "\n",
    "# State with the highest poverty percentage\n",
    "state_highest_poverty = df_poverty.loc[df_poverty['povertyPercentage'].idxmax()]\n",
    "print(\"State with the highest poverty percentage:\")\n",
    "print(state_highest_poverty)\n",
    "highest_poverty_percentage = state_highest_poverty['povertyPercentage']\n",
    "print(f\"Value: {highest_poverty_percentage}%\")\n",
    "\n",
    "# State with the lowest poverty percentage\n",
    "state_low_poverty = df_poverty.loc[df_poverty['povertyPercentage'].idxmin()]\n",
    "print(\"State with the lowest poverty percentage:\")\n",
    "print(state_low_poverty)\n",
    "low_poverty_percentage = state_low_poverty['povertyPercentage']\n",
    "print(f\"Value: {low_poverty_percentage}%\")\n",
    "\n",
    "# Histogram\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df_poverty_filtered['povertyPercentage'], bins=20, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Poverty Percentage')\n",
    "plt.xlabel('Poverty Percentage')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Percentiles (Q1, Median, Q3)\n",
    "percentiles = np.percentile(df_poverty_filtered['povertyPercentage'], [25, 50, 75])\n",
    "print(\"Percentiles (Q1, Median, Q3):\", percentiles)\n",
    "\n",
    "# Now with the DataFrame of 2012 percPov reconstructed via median: poverty_fil_perc\n",
    "# Calculate the median of povertyPercentage for each year\n",
    "mean_pov = poverty_fil_perc.groupby('year')['povertyPercentage'].mean().reset_index()\n",
    "\n",
    "# Plot the line graph showing the mean of povertyPercentage for all states\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=mean_pov, x='year', y='povertyPercentage', marker='o', color='skyblue')\n",
    "plt.title('Mean of Poverty Percentage per Year (All States)(with median)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Poverty Percentage')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVING THE NaNs for the years 2012 the shape of the distribution(mean(povertyPercentage)) give us a coherent distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the year is 2012\n",
    "df_poverty_noNan = df_poverty_filtered[df_poverty_filtered['year'] != 2012]\n",
    "\n",
    "# Filter the DataFrame for the year 2012 only\n",
    "year_2012 = df_prova[df_prova['year'] == 2012]\n",
    "print(year_2012.head()[['state', 'povertyPercentage']])\n",
    "\n",
    "# Calculate the median of 'povertyPercentage' for each year\n",
    "mean_pov = df_poverty_noNan.groupby('year')['povertyPercentage'].mean().reset_index()\n",
    "\n",
    "# Line plot of the average 'povertyPercentage' for all states over the years\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=mean_pov, x='year', y='povertyPercentage', marker='o', color='skyblue')\n",
    "plt.title('Average Poverty Percentage per Year (All States)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Poverty Percentage')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'povertyPercentage' in descending order\n",
    "df_poverty_sorted = df_poverty_noNan.sort_values(by='povertyPercentage', ascending=False)\n",
    "print(df_poverty_sorted)\n",
    "\n",
    "# Create a bar chart showing the poverty percentage for each state\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(df_poverty_sorted['state'], df_poverty_sorted['povertyPercentage'], color='skyblue')\n",
    "plt.title('Poverty Percentage per State (Sorted)')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Poverty Percentage')\n",
    "plt.xticks(rotation=90, ha='right')  # Rotate state labels for better readability\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "\n",
    "# Set display options to show all rows and columns for better visibility\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df_poverty_sorted)\n",
    "\n",
    "# Reset back to default options after printing\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize `povertyByStateYear` dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# dataset poverty\n",
    "df_poverty = pd.read_csv('../source/ds/povertyByStateYear.csv')\n",
    "\n",
    "df_poverty.head()\n",
    "\n",
    "# Create dictionary state (two letter)\n",
    "dict_state = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "} \n",
    "\n",
    "print(\"number of states\", len(df_poverty[df_poverty.state!='United States'].state.unique()))\n",
    "\n",
    "poverties = df_poverty[df_poverty.state!='United States'].groupby('state').povertyPercentage.mean()\n",
    "states = df_poverty[df_poverty.state!='United States'].state.unique()\n",
    "states_abb = [dict_state[st] for st in df_poverty[df_poverty.state != 'United States'].state.unique()]\n",
    "fig= px.choropleth(locations=states_abb, locationmode='USA-states', color=poverties, scope='usa', color_continuous_scale='Reds', range_color=(np.min(poverties), np.max(poverties)), title='Mean poverty percentage per state in USA')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final cleaning on poverty dataset\n",
    "\n",
    "Given that the incidents dataset starts from 2013, we'll remove rows from the current poverty dataframe where the year value is less than 2012 (*as 2012 data has already been removed*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final cleaning on poverty dataset\n",
    "df_poverty_before_merge = df_poverty_noNan[df_poverty_noNan['year'] > 2013]\n",
    "# check the range of the years\n",
    "anno_minimo = df_poverty_before_merge['year'].min()\n",
    "anno_massimo = df_poverty_before_merge['year'].max()\n",
    "print(f\"The range of years is {anno_minimo};{anno_massimo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poverty_before_merge.groupby('year').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../source/ds/df_povery_cleaned.csv\"\n",
    "df_poverty_before_merge.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Task 1.1 - Data Understanding `year_state_district_house.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Year-state-district-house\n",
    "df_ys = pd.read_csv('../source/ds/year_state_district_house.csv')\n",
    "\n",
    "print(df_ys.head())\n",
    "print(df_ys.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Party\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the column `party` in categorical since it is object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ys['party'] = df_ys['party'].astype('category')\n",
    "print(df_ys.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values for each column\n",
    "print(\"##########################################\")\n",
    "print(\"Counts unique values for each column\")\n",
    "print(df_ys.nunique())\n",
    "print(\"##########################################\")\n",
    "\n",
    "# List all the unique values for the 'party' feature\n",
    "print(\"List of all the values for the feature 'party'\")\n",
    "unique_party_values = df_ys['party'].unique()\n",
    "print(unique_party_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerations about `party` values\n",
    "The value `FOGLIETTA (DEMOCRAT)` is a democrat candidate but wrongly inserted as a party so it's replaced `DEMOCRAT`.\n",
    "\n",
    "Also `DEMOCRATIC-FARMER-LABOR` need to be replaced because is just local affiliate of the natioal party, so it's replaced by `DEMOCRAT`.\n",
    "The value `INDEPENDENT-REPUBLICAN` is a better specification on **INDEPENDET** will keep just `INDEPENDENT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ys.replace({'FOGLIETTA (DEMOCRAT)': 'DEMOCRAT'}, inplace=True)\n",
    "df_ys.replace({'DEMOCRATIC-FARMER-LABOR': 'DEMOCRAT'}, inplace=True)\n",
    "df_ys.replace({'INDEPENDENT-REPUBLICAN': 'INDEPENDENT'}, inplace=True)\n",
    "\n",
    "print(\"##########################################\")\n",
    "print(\"Counts unique values for each column\")\n",
    "print(df_ys.nunique())\n",
    "print(\"##########################################\")\n",
    "print(\"List of alle the values for the feature 'party'\")\n",
    "unique_state_values = df_ys['party'].unique()\n",
    "print(unique_state_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `state` attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the `state` are the totality of the states in USA and format the state names in a correct format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"##########################################\")\n",
    "unique_state_values = df_ys['state'].unique()\n",
    "print(unique_state_values)\n",
    "\n",
    "#Change the format of `state` to be able to merge with the other two dataset later, in Data Preparation\n",
    "def capitalize_first_letter(word):\n",
    "        # Split the string into words\n",
    "    words = word.split()\n",
    "    \n",
    "    # Capitalize the first letter of each word and lowercase the rest\n",
    "    capitalized_words = [w.capitalize() for w in words]\n",
    "    \n",
    "    # Join the words back together\n",
    "    return ' '.join(capitalized_words)\n",
    "\n",
    "df_ys['state'] = df_ys['state'].apply(capitalize_first_letter)\n",
    "print(df_ys['state'].nunique())\n",
    "\n",
    "#Recompute to we mantain all the states\n",
    "unique_state_values = df_ys['state'].unique()\n",
    "print(unique_state_values)\n",
    "\n",
    "for state in dict_state:\n",
    "    if state not in unique_state_values:\n",
    "        print(\"Missing state:\" + state)\n",
    "#print(unique_state_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `year` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value_year = df_ys['year'].max()\n",
    "min_value_year = df_ys['year'].min()\n",
    "print(f\"The range of the year for this dataset is {min_value_year};{max_value_year}\")\n",
    "#range of poverty ds is year 2004-2020\n",
    "\n",
    "# Print max and min year values\n",
    "print(\"Min year:\", min_value_year)\n",
    "print(\"Max year:\", max_value_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to highlight that the `date` in `incidents` dataset ranges from 2013 to 2020, the same for  `povertyByState` cleaned ranges from 2013 to 2020; differently, for `state house` the year range is from 1976 to 2020.\n",
    "We decided to remove the record that refer the years from 76-2013 as are not useful for our purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ys_date = df_ys[df_ys['year'] > 2013]\n",
    "max_value_year = df_ys_date['year'].max()\n",
    "min_value_year = df_ys_date['year'].min()\n",
    "print(f\"The range of the year for this dataset is {min_value_year};{max_value_year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also noticed that there is no data related to party wins in 2013 because there were no elections/polls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check on null values  and duplicates for the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stampa il numero di valori nulli per ciascuna colonna\n",
    "print(df_ys_date.isnull().sum())\n",
    "\n",
    "# Controlla i valori duplicati in tutto il DataFrame\n",
    "duplicati = df_ys_date.duplicated()\n",
    "\n",
    "# Stampa le righe duplicate\n",
    "print(\"Righe duplicate:\")\n",
    "print(df_ys_date[duplicati])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `congressional_district` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_values = df_ys_date[df_ys_date['congressional_district'] == 0]\n",
    "\n",
    "# Stampa le righe risultanti\n",
    "print(\"Righe con 'congressional_district' uguale a zero:\")\n",
    "print(zero_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop zero values from congressional district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_val = df_ys_date[df_ys_date['congressional_district'] == 0]\n",
    "# Stampa le righe risultanti\n",
    "print(\"Righe con 'congressional_district' uguale a zero:\")\n",
    "print(len(zero_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT remove column distrectional_district\n",
    "# Pefrom check on congressional_district value per year per state to be able to derive insights when merging with incidents respect to\n",
    "# most violent district, which is the political preference of the most violent district, etc.\n",
    "#df_ys_date_no_congress = df_ys_date.drop(columns=['congressional_district'])\n",
    "\n",
    "\n",
    "df_ys_date_no_congress =  df_ys_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerations about `totalvotes`, `candidatevotes`\n",
    "We may try to extract some insights like if in a given state a party have more votes but at the same time the opposition party gained the State Federal Goverment seat as they won the majority of the district.\n",
    "At the end, we can drop the two column and aggregate,for each year and each state, the winner party, renaming the column in `winner_party`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if the two columns have zero values\n",
    "print(np.count_nonzero(df_ys_date['totalvotes']==0))\n",
    "print(np.count_nonzero(df_ys_date['candidatevotes']==0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# totalvotes and candidatevotes\n",
    "independently from the presence of missing values, dulìplicated, out of range values, ... -> we drop the theese two columns since are not useful for our task: considerations can be done within the dataset (like electors have partecipated to the polls) but not useful for the global considerations driven by the merge of the whole 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ys_date_no_candidate = df_ys_date_no_congress.drop(columns=['candidatevotes'])\n",
    "#df_ys_date_no_total_votes = df_ys_date_no_candidate.drop(columns=['totalvotes'])\n",
    "#print(df_ys_date_no_total_votes.head())\n",
    "#df_ys_cleaned=df_ys_date_no_total_votes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DS is cleaned: use df_ys_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of party winning in each states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vedere quante volte c'è un singolo partito ha vinto negli anni per ogni stato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So at this point we have the party winners in each state for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dato che alla fine non abbiamo tolto totalvotes and candidate votes ricopio il dataset altrimenti si rompe\n",
    "df_ys_cleaned = df_ys_date\n",
    "# Raggruppa per 'state', 'party' e conta le occorrenze\n",
    "conteggio_vittorie = df_ys_cleaned.groupby(['state', 'party', 'year']).size().reset_index(name='conteggio')\n",
    "print(conteggio_vittorie)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "#GRAFICO a torta per vedere la per ogni stato la percentuale di vittorie che ha raggiunto ogni ogni partito\n",
    "for stato in df_ys_cleaned['state'].unique():\n",
    "    # Filtra il DataFrame per uno stato specifico\n",
    "    df_stato = conteggio_vittorie[conteggio_vittorie['state'] == stato]\n",
    "\n",
    "    # Crea un diagramma a torta per lo stato corrente\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.pie(df_stato['conteggio'], labels=df_stato['party'], autopct='%1.1f%%', startangle=90)\n",
    "    plt.title(f'Party Wins in {stato}')\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo dropperei, quando lo fatto sembrava sembrava avesse ma ora sembra non abbia senso\n",
    "\"\"\"\n",
    "# Raggruppa i dati per 'state' e 'party' e conta il numero di occorrenze\n",
    "grouped_data = df_ys_date.groupby(['state', 'party']).size().unstack()\n",
    "\n",
    "# Visualizza un grafico a barre\n",
    "grouped_data.plot(kind='bar', stacked=True, figsize=(15, 8))\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Number of Occurrences')\n",
    "plt.title('Party Wins by State')\n",
    "plt.legend(title='Party', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "conteggio_party_per_stato = df_ys_date .groupby(['state', 'party']).size().reset_index(name='conteggio')\n",
    "# Visualizza il conteggio\n",
    "print(conteggio_party_per_stato)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: fare considerazioni sui numeri e su informazioni aggiuntive \n",
    "#occ per la combinazione di year e party\n",
    "wins_per_year = df_ys_date.groupby(['year', 'party']).size().reset_index(name='cont')\n",
    "# Pivot: 'party' come colonne\n",
    "pivot_df = wins_per_year.pivot(index='year', columns='party', values='cont').fillna(0)\n",
    "pivot_df.plot(kind='line', figsize=(15, 8))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Wins per district')\n",
    "plt.title('Party Wins Over the Years')\n",
    "plt.legend(title='Party', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mean_wins_party = wins_per_year.groupby('party')['cont'].mean().reset_index()\n",
    "dev_st_wins_party = wins_per_year.groupby('party')['cont'].std().reset_index()\n",
    "\n",
    "print(\"Mean wins per party:\")\n",
    "print(mean_wins_party)\n",
    "\n",
    "print(\"\\nstnd deviation wins per party:\")\n",
    "print(dev_st_wins_party)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO WE KEEP JUST BEFORE THE MERGING THE COLUMNS FOR TOTAL VOTES AND CANDIDATE VOTES BUT WE ARE NOT ABLE TO MAKE CHECKS ON THE RANGE AND EFFECTIVE VALUES FOR THOOSE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPORT the dataset: df_ys_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ys_date['state'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"../source/ds/df_yearState.csv\"\n",
    "df_ys_date.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

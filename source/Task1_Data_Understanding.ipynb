{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.1: Data Understanding\n",
    "\n",
    "Explore the incidents dataset using analytical tools and write a concise \"data understanding\" report that assesses data quality, the distribution of variables, and pairwise correlations.\n",
    "\n",
    "Subtasks of Data Understanding:\n",
    "\n",
    "- Data semantics for each feature not described above and the new ones defined by the team\n",
    "- Distribution of the variables and statistics\n",
    "- Assessing data quality (missing values, outliers, duplicated records, errors)\n",
    "- Variables transformations\n",
    "- Pairwise correlations and eventual elimination of redundant variables\n",
    "\n",
    "Nice visualization and insights can be obtained by exploiting the latitude and longitude features ([example](https://plotly.com/python/getting-started/)).\n",
    "\n",
    "For this task we followed the following check structure [#WIP]():\n",
    "1. [] Type of data\n",
    "2. [x] Type of attribute\n",
    "3. [] Data Quality\n",
    "4. [ ] Outliers detection and manipulation\n",
    "5. [ ] Correlation analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.2: Data Preparation\n",
    "\n",
    "Improve the quality of your data and prepare it by extracting new features interesting for describing the incidents. Some examples of indicators to be computed are:\n",
    "\n",
    "- How many males are involved in incidents relative to the total number of males for the same city and in the same period?\n",
    "- How many injured and killed people have been involved relative to the total injured and killed people in the same congressional district in a given period of time?\n",
    "- Ratio of the number of killed people in the incidents relative to the number of participants in the incident\n",
    "- Ratio of unharmed people in the incidents relative to the average of unharmed people in the same period\n",
    "\n",
    "Note that these examples are not mandatory, and teams can define their own indicators. Each indicator must be correlated with a description and, when necessary, its mathematical formulation. The extracted variables will be useful for the clustering analysis in the second project's task. Once the set of indicators is computed, the team should explore the new features for a statistical analysis, including distributions, outliers, visualizations, and correlations.\n",
    "\n",
    "See the corresponding Notebook in [Task 1.2 - Data Preparation](Task1_Data_Preparation.ipynb).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.1 - Data Understanding `incident.csv`\n",
    "\n",
    "We have to do some data understanding, so we're gonna explore the dataset. We can start with a simple analysis that establish the variable inside our dataset and visualize a bunch of their distibution, type, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take a while\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import plotly.offline as py\n",
    "\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Structure\n",
    "\n",
    "Let's breakdown the first, larger dataset `incidents.csv` by describing briefly the general structure:\n",
    "- 28 Columns features: Some categorical like `date`, `state` etc... Others are numerical like `n_participants, n_males` despite the type must be still checked. \n",
    "- Textual features like `notes`, `incident_characteristics1` and `incident_characteristics2` will be firstly analyzed but, at first look, are not much useful when combined with other dataset as the information reported are fragmented/incorrect/ambiguous. \n",
    "\n",
    "Let's import all the three dataset, starting to analyze first the larger one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10494/2572660480.py:4: DtypeWarning:\n",
      "\n",
      "Columns (15,16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>city_or_county</th>\n",
       "      <th>address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>congressional_district</th>\n",
       "      <th>state_house_district</th>\n",
       "      <th>state_senate_district</th>\n",
       "      <th>participant_age1</th>\n",
       "      <th>...</th>\n",
       "      <th>n_males</th>\n",
       "      <th>n_females</th>\n",
       "      <th>n_killed</th>\n",
       "      <th>n_injured</th>\n",
       "      <th>n_arrested</th>\n",
       "      <th>n_unharmed</th>\n",
       "      <th>n_participants</th>\n",
       "      <th>notes</th>\n",
       "      <th>incident_characteristics1</th>\n",
       "      <th>incident_characteristics2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>Lafayette Road and Pike Plaza</td>\n",
       "      <td>39.8322</td>\n",
       "      <td>-86.2492</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Teen wounded while walking - Security guard at...</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Kane</td>\n",
       "      <td>5647 US 6</td>\n",
       "      <td>41.6645</td>\n",
       "      <td>-78.7856</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>shot self after accident</td>\n",
       "      <td>Shot - Dead (murder, accidental, suicide)</td>\n",
       "      <td>Suicide^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>6200 Block of East McNichols Road</td>\n",
       "      <td>42.4190</td>\n",
       "      <td>-83.0393</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 inj.</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>Washington</td>\n",
       "      <td>1000 block of Bladensburg Road, NE</td>\n",
       "      <td>38.9030</td>\n",
       "      <td>-76.9820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030-06-14</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>California and Marshall Avenues</td>\n",
       "      <td>40.4621</td>\n",
       "      <td>-80.0308</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>Drive-by (car to street, car to car)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-01-18</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Wayne County</td>\n",
       "      <td>4700 block of U.S. Highway 70 East</td>\n",
       "      <td>35.1847</td>\n",
       "      <td>-77.9527</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>Home Invasion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Zachary</td>\n",
       "      <td>18733 Samuels Rd</td>\n",
       "      <td>30.6069</td>\n",
       "      <td>-91.2270</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Good Samaritan shot aggressors - was arrested ...</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>Shot - Dead (murder, accidental, suicide)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-03-16</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>560 Ella T Grasso Boulevard</td>\n",
       "      <td>41.2945</td>\n",
       "      <td>-72.9457</td>\n",
       "      <td>3.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>student hid Ruger 357 gun in coat, no shots fired</td>\n",
       "      <td>Institution/Group/Business</td>\n",
       "      <td>Non-Shooting Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Stafford</td>\n",
       "      <td>Cool Springs Road and North Kings Highway</td>\n",
       "      <td>38.3008</td>\n",
       "      <td>-77.4469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>car crash, suspect holding handgun, officers s...</td>\n",
       "      <td>Shot - Dead (murder, accidental, suicide)</td>\n",
       "      <td>Officer Involved Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-03-22</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Tulsa</td>\n",
       "      <td>12500 block of East 52nd Street</td>\n",
       "      <td>36.1060</td>\n",
       "      <td>-96.0764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Super 8 Motel</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>Accidental Shooting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>New York</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>East 194th Street</td>\n",
       "      <td>40.8524</td>\n",
       "      <td>-73.8310</td>\n",
       "      <td>14.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>shot outside Bodega, Warren also wanted for Oc...</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-12-21</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>Kansas City (Raytown)</td>\n",
       "      <td>6500 block of Raytown Road</td>\n",
       "      <td>38.9647</td>\n",
       "      <td>-94.4654</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Suspect fired shots at another man; no shots f...</td>\n",
       "      <td>Shots Fired - No Injuries</td>\n",
       "      <td>Officer Involved Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>California</td>\n",
       "      <td>Hesperia</td>\n",
       "      <td>7700 block of Foley Rd</td>\n",
       "      <td>34.3904</td>\n",
       "      <td>-117.3770</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shot - Dead (murder, accidental, suicide)</td>\n",
       "      <td>House party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-02-17</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Longview</td>\n",
       "      <td>831 Noel Dr</td>\n",
       "      <td>32.4862</td>\n",
       "      <td>-94.7206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>cash, drugs, 5 guns incl 2 stolen pistols</td>\n",
       "      <td>Non-Shooting Incident</td>\n",
       "      <td>Drug involvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-08-26</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Asheville</td>\n",
       "      <td>Quigley Dr</td>\n",
       "      <td>35.5531</td>\n",
       "      <td>-82.6248</td>\n",
       "      <td>11.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Buncombe Co, hi, fired shots in home, no inj</td>\n",
       "      <td>Shots Fired - No Injuries</td>\n",
       "      <td>Home Invasion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2030-07-03</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Laredo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.5144</td>\n",
       "      <td>-99.4994</td>\n",
       "      <td>28.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Shooting Incident</td>\n",
       "      <td>Possession of gun by felon or prohibited person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2029-07-11</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>English Drive</td>\n",
       "      <td>41.3251</td>\n",
       "      <td>-72.9037</td>\n",
       "      <td>3.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shots Fired - No Injuries</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016-02-14</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>1100 block of South Mole Street</td>\n",
       "      <td>39.9372</td>\n",
       "      <td>-75.1699</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Shooting Incident</td>\n",
       "      <td>Home Invasion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-05-27</td>\n",
       "      <td>California</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>South Central Avenue 7500 block</td>\n",
       "      <td>33.9722</td>\n",
       "      <td>-118.2560</td>\n",
       "      <td>40.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shot - Dead (murder, accidental, suicide)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016-07-08</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>500 block of North Lavergne</td>\n",
       "      <td>41.8895</td>\n",
       "      <td>-87.7507</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Austin - 1 killed, 2 stable;</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>Shot - Dead (murder, accidental, suicide)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                 state         city_or_county  \\\n",
       "0   2015-05-02               Indiana           Indianapolis   \n",
       "1   2017-04-03          Pennsylvania                   Kane   \n",
       "2   2016-11-05              Michigan                Detroit   \n",
       "3   2016-10-15  District of Columbia             Washington   \n",
       "4   2030-06-14          Pennsylvania             Pittsburgh   \n",
       "5   2014-01-18        North Carolina           Wayne County   \n",
       "6   2018-01-25             Louisiana                Zachary   \n",
       "7   2016-03-16           Connecticut              New Haven   \n",
       "8   2016-08-01              Virginia               Stafford   \n",
       "9   2015-03-22              Oklahoma                  Tulsa   \n",
       "10  2014-06-19              New York                  Bronx   \n",
       "11  2016-12-21              Missouri  Kansas City (Raytown)   \n",
       "12  2018-01-06            California               Hesperia   \n",
       "13  2017-02-17                 Texas               Longview   \n",
       "14  2016-08-26        North Carolina              Asheville   \n",
       "15  2030-07-03                 Texas                 Laredo   \n",
       "16  2029-07-11           Connecticut              New Haven   \n",
       "17  2016-02-14          Pennsylvania           Philadelphia   \n",
       "18  2014-05-27            California            Los Angeles   \n",
       "19  2016-07-08              Illinois                Chicago   \n",
       "\n",
       "                                      address  latitude  longitude  \\\n",
       "0               Lafayette Road and Pike Plaza   39.8322   -86.2492   \n",
       "1                                   5647 US 6   41.6645   -78.7856   \n",
       "2           6200 Block of East McNichols Road   42.4190   -83.0393   \n",
       "3          1000 block of Bladensburg Road, NE   38.9030   -76.9820   \n",
       "4             California and Marshall Avenues   40.4621   -80.0308   \n",
       "5          4700 block of U.S. Highway 70 East   35.1847   -77.9527   \n",
       "6                            18733 Samuels Rd   30.6069   -91.2270   \n",
       "7                 560 Ella T Grasso Boulevard   41.2945   -72.9457   \n",
       "8   Cool Springs Road and North Kings Highway   38.3008   -77.4469   \n",
       "9             12500 block of East 52nd Street   36.1060   -96.0764   \n",
       "10                          East 194th Street   40.8524   -73.8310   \n",
       "11                 6500 block of Raytown Road   38.9647   -94.4654   \n",
       "12                     7700 block of Foley Rd   34.3904  -117.3770   \n",
       "13                                831 Noel Dr   32.4862   -94.7206   \n",
       "14                                 Quigley Dr   35.5531   -82.6248   \n",
       "15                                        NaN   27.5144   -99.4994   \n",
       "16                              English Drive   41.3251   -72.9037   \n",
       "17            1100 block of South Mole Street   39.9372   -75.1699   \n",
       "18           South Central Avenue 7500 block    33.9722  -118.2560   \n",
       "19                500 block of North Lavergne   41.8895   -87.7507   \n",
       "\n",
       "    congressional_district  state_house_district  state_senate_district  \\\n",
       "0                      7.0                  94.0                   33.0   \n",
       "1                      5.0                   NaN                    NaN   \n",
       "2                     14.0                   4.0                    2.0   \n",
       "3                      1.0                   NaN                    NaN   \n",
       "4                     14.0                   NaN                    NaN   \n",
       "5                     13.0                   4.0                    7.0   \n",
       "6                      6.0                  63.0                   15.0   \n",
       "7                      3.0                 116.0                   10.0   \n",
       "8                      1.0                  28.0                   28.0   \n",
       "9                      1.0                  66.0                   37.0   \n",
       "10                    14.0                  82.0                   34.0   \n",
       "11                     5.0                  29.0                    9.0   \n",
       "12                     8.0                  33.0                   21.0   \n",
       "13                     1.0                   NaN                    1.0   \n",
       "14                    11.0                 116.0                   49.0   \n",
       "15                    28.0                  42.0                   21.0   \n",
       "16                     3.0                  96.0                   11.0   \n",
       "17                     2.0                   NaN                    NaN   \n",
       "18                    40.0                  59.0                   33.0   \n",
       "19                     7.0                   8.0                    4.0   \n",
       "\n",
       "    participant_age1  ... n_males n_females n_killed n_injured n_arrested  \\\n",
       "0               19.0  ...     1.0       0.0        0         1        0.0   \n",
       "1               62.0  ...     1.0       0.0        1         0        0.0   \n",
       "2                NaN  ...     NaN       NaN        0         1        0.0   \n",
       "3                NaN  ...     1.0       0.0        0         1        0.0   \n",
       "4                NaN  ...     1.0       0.0        0         1        0.0   \n",
       "5               65.0  ...     1.0       0.0        0         1        0.0   \n",
       "6               30.0  ...     5.0       0.0        2         1        2.0   \n",
       "7                NaN  ...     1.0       0.0        0         0        1.0   \n",
       "8               65.0  ...     1.0       0.0        1         0        0.0   \n",
       "9               20.0  ...     0.0       1.0        0         1        0.0   \n",
       "10              31.0  ...     3.0       0.0        0         1        2.0   \n",
       "11              29.0  ...     1.0       0.0        0         0        1.0   \n",
       "12              19.0  ...     1.0       0.0        1         0        0.0   \n",
       "13              36.0  ...     4.0       0.0        0         0        4.0   \n",
       "14               NaN  ...     1.0       0.0        0         0        1.0   \n",
       "15               NaN  ...     1.0       0.0        0         0        1.0   \n",
       "16               NaN  ...     2.0       0.0        0         0        0.0   \n",
       "17              39.0  ...     2.0       1.0        0         0        1.0   \n",
       "18              48.0  ...     2.0       0.0        1         0        0.0   \n",
       "19              59.0  ...     3.0       0.0        1         2        0.0   \n",
       "\n",
       "   n_unharmed n_participants  \\\n",
       "0         0.0            1.0   \n",
       "1         0.0            1.0   \n",
       "2         1.0            2.0   \n",
       "3         0.0            2.0   \n",
       "4         1.0            2.0   \n",
       "5         0.0            1.0   \n",
       "6         0.0            5.0   \n",
       "7         0.0            1.0   \n",
       "8         0.0            1.0   \n",
       "9         0.0            1.0   \n",
       "10        0.0            3.0   \n",
       "11        0.0            1.0   \n",
       "12        0.0            1.0   \n",
       "13        0.0            4.0   \n",
       "14        0.0            1.0   \n",
       "15        0.0            1.0   \n",
       "16        2.0            2.0   \n",
       "17        2.0            3.0   \n",
       "18        1.0            2.0   \n",
       "19        0.0            3.0   \n",
       "\n",
       "                                                notes  \\\n",
       "0   Teen wounded while walking - Security guard at...   \n",
       "1                            shot self after accident   \n",
       "2                                              1 inj.   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6   Good Samaritan shot aggressors - was arrested ...   \n",
       "7   student hid Ruger 357 gun in coat, no shots fired   \n",
       "8   car crash, suspect holding handgun, officers s...   \n",
       "9                                       Super 8 Motel   \n",
       "10  shot outside Bodega, Warren also wanted for Oc...   \n",
       "11  Suspect fired shots at another man; no shots f...   \n",
       "12                                                NaN   \n",
       "13          cash, drugs, 5 guns incl 2 stolen pistols   \n",
       "14       Buncombe Co, hi, fired shots in home, no inj   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                       Austin - 1 killed, 2 stable;   \n",
       "\n",
       "                    incident_characteristics1  \\\n",
       "0                      Shot - Wounded/Injured   \n",
       "1   Shot - Dead (murder, accidental, suicide)   \n",
       "2                      Shot - Wounded/Injured   \n",
       "3                      Shot - Wounded/Injured   \n",
       "4                      Shot - Wounded/Injured   \n",
       "5                      Shot - Wounded/Injured   \n",
       "6                      Shot - Wounded/Injured   \n",
       "7                  Institution/Group/Business   \n",
       "8   Shot - Dead (murder, accidental, suicide)   \n",
       "9                      Shot - Wounded/Injured   \n",
       "10                     Shot - Wounded/Injured   \n",
       "11                  Shots Fired - No Injuries   \n",
       "12  Shot - Dead (murder, accidental, suicide)   \n",
       "13                      Non-Shooting Incident   \n",
       "14                  Shots Fired - No Injuries   \n",
       "15                      Non-Shooting Incident   \n",
       "16                  Shots Fired - No Injuries   \n",
       "17                      Non-Shooting Incident   \n",
       "18  Shot - Dead (murder, accidental, suicide)   \n",
       "19                     Shot - Wounded/Injured   \n",
       "\n",
       "                          incident_characteristics2  \n",
       "0                                               NaN  \n",
       "1                                          Suicide^  \n",
       "2                                               NaN  \n",
       "3                                               NaN  \n",
       "4              Drive-by (car to street, car to car)  \n",
       "5                                     Home Invasion  \n",
       "6         Shot - Dead (murder, accidental, suicide)  \n",
       "7                             Non-Shooting Incident  \n",
       "8                         Officer Involved Incident  \n",
       "9                               Accidental Shooting  \n",
       "10                                              NaN  \n",
       "11                        Officer Involved Incident  \n",
       "12                                      House party  \n",
       "13                                 Drug involvement  \n",
       "14                                    Home Invasion  \n",
       "15  Possession of gun by felon or prohibited person  \n",
       "16                                              NaN  \n",
       "17                                    Home Invasion  \n",
       "18                                              NaN  \n",
       "19        Shot - Dead (murder, accidental, suicide)  \n",
       "\n",
       "[20 rows x 28 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the datasets\n",
    "\n",
    "# Gun incidents data\n",
    "df_incidents = pd.read_csv('../source/ds/incidents.csv')\n",
    "\n",
    "# Poverty by state and year\n",
    "df_poverty = pd.read_csv('../source/ds/povertyByStateYear.csv')\n",
    "\n",
    "# Year-state-district-house\n",
    "df_ysdh = pd.read_csv('../source/ds/year_state_district_house.csv')\n",
    "\n",
    "\n",
    "# Visualize data table\n",
    "df_incidents.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first look there are values whose the type is not matching or is ambiguous, so we delve deeper into this aspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 884 entries, 0 to 883\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   state              884 non-null    object \n",
      " 1   year               884 non-null    int64  \n",
      " 2   povertyPercentage  832 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 20.8+ KB\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10441 entries, 0 to 10440\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   year                    10441 non-null  int64 \n",
      " 1   state                   10441 non-null  object\n",
      " 2   congressional_district  10441 non-null  int64 \n",
      " 3   party                   10441 non-null  object\n",
      " 4   candidatevotes          10441 non-null  int64 \n",
      " 5   totalvotes              10441 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 489.5+ KB\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 239677 entries, 0 to 239676\n",
      "Data columns (total 28 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   date                       239677 non-null  object \n",
      " 1   state                      239677 non-null  object \n",
      " 2   city_or_county             239677 non-null  object \n",
      " 3   address                    223180 non-null  object \n",
      " 4   latitude                   231754 non-null  float64\n",
      " 5   longitude                  231754 non-null  float64\n",
      " 6   congressional_district     227733 non-null  float64\n",
      " 7   state_house_district       200905 non-null  float64\n",
      " 8   state_senate_district      207342 non-null  float64\n",
      " 9   participant_age1           147379 non-null  float64\n",
      " 10  participant_age_group1     197558 non-null  object \n",
      " 11  participant_gender1        203315 non-null  object \n",
      " 12  min_age_participants       164879 non-null  object \n",
      " 13  avg_age_participants       165057 non-null  object \n",
      " 14  max_age_participants       164969 non-null  object \n",
      " 15  n_participants_child       197573 non-null  object \n",
      " 16  n_participants_teen        197578 non-null  object \n",
      " 17  n_participants_adult       197575 non-null  object \n",
      " 18  n_males                    203315 non-null  float64\n",
      " 19  n_females                  203315 non-null  float64\n",
      " 20  n_killed                   239677 non-null  int64  \n",
      " 21  n_injured                  239677 non-null  int64  \n",
      " 22  n_arrested                 212051 non-null  float64\n",
      " 23  n_unharmed                 212051 non-null  float64\n",
      " 24  n_participants             239677 non-null  float64\n",
      " 25  notes                      158660 non-null  object \n",
      " 26  incident_characteristics1  239351 non-null  object \n",
      " 27  incident_characteristics2  141931 non-null  object \n",
      "dtypes: float64(11), int64(2), object(15)\n",
      "memory usage: 51.2+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"--\"*50)\n",
    "df_poverty.info()\n",
    "print(\"--\"*50)\n",
    "df_ysdh.info()\n",
    "print(\"--\"*50)\n",
    "df_incidents.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Quality [#WIP]()\n",
    "In this section we evaluate the following:\n",
    "- **Syntacic accuracy**: if the domain value of the attributes is respected\n",
    "- **Semantic accuracy**: correct attribute value\n",
    "- **Completeness**: if the samples cover the all the possible value of the attribute\n",
    "- **Unbalanced data**: understand if all the record represents all the possible scenarios the dataset want describe, equally\n",
    "- **Timeliness**: understand if data are coherent respect to the timeframe considered\n",
    "\n",
    "It's necessary to highlight also the importance of __eliminate duplicate data, plot the histogram visualization for frequency distribution and measure the central tendency (_AAD,MAD_)__. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `describe` return basic statistics for numerical attributes: at first look, are missing multiple attributes because some of the expected numerical attributes are of type `object`. Also, most of the attributes shown are `float64` despite the expected numerical range is an `int64`. \n",
    "\n",
    "Aside from that, still without much pre-processing we can understand that:\n",
    "- `congressional_district`: the min and max value return a correct domain for the attribute as the state with most congressional district is the state of California.\n",
    "- `state_house_district`: the min and max value shows an _incorrect_ domain as the state with most state house district is the New Hampshire with 400 district, not 901.\n",
    "- `state_senate_district`: the min and max value shows an _incorrect_ domain as the state with most state senate district is the Minnesota with 67 district, not 94.\n",
    "- `partecipant_age1`:  the max age shows the presence of noise data with age over 300.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.1 Data Conversions\n",
    "\n",
    "All of the following attributes are `object` or `float64` so we convert them to `int64`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - avg_age_participants, min_age_participants, max_age_participants, n_participant_child, n_participant_teen, n_participant_adult: are all object time, convert them to int\n",
    "columns_to_convert = [\n",
    "    'min_age_participants',\n",
    "    'avg_age_participants',\n",
    "    'max_age_participants',\n",
    "    'n_participants_child',\n",
    "    'n_participants_teen',\n",
    "    'n_participants_adult'\n",
    "]\n",
    "\n",
    "district_to_int = ['state_house_district', 'state_senate_district', 'congressional_district']\n",
    "\n",
    "# Convert non-numeric values to NaN\n",
    "df_incidents[columns_to_convert] = df_incidents[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "for column in district_to_int:\n",
    "    df_incidents[column] = df_incidents[column].fillna(0).astype(int)\n",
    "    \n",
    "# Fill NaN values with 0\n",
    "df_incidents[columns_to_convert] = df_incidents[columns_to_convert].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "df_incidents.dtypes\n",
    "df_incidents.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type conversion shows all the expected numerical column, highlighting that:\n",
    "- `min_age_partecipants`: shows noise data with age -1000 and max age over 8 billion. Similar behaviour is inevitably also found for attributes `avg_age_partecipants, max_age_partecipants`\n",
    "- `n_partecipants_child`,`n_partecipants_teen` and `n_participants_adult`: min value cannot be negative and max value is over the (_un-processed_) dataset size of 239677 records.\n",
    "\n",
    "Other consistency checks are performed after the dataset has been manipulated from noise and outlier records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEFORE DOING THIS REMOVE NA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop na\n",
    "df_incidents = df_incidents.dropna()\n",
    "\n",
    "\n",
    "# Let's ajdust the numbers here\n",
    "# age can be only from 0 to 100 we remove all the other values\n",
    "print(\"Number of incidents before cleaning\", df_incidents.shape[0])\n",
    "\n",
    "df_incidents = df_incidents[df_incidents['participant_age1'] <= 100]\n",
    "\n",
    "print(\"Number of incidents after cleaning\", df_incidents.shape[0])\n",
    "\n",
    "\n",
    "# remove NA before doing THIS\n",
    "\n",
    "# Set to integer all the columns that are age or min and max or num participants\n",
    "columns_to_convert_int = [\"participant_age1\", \"avg_age_participants\", \n",
    "                          \"min_age_participants\", \"max_age_participants\", \n",
    "                          \"n_participants_child\", \"n_participants_teen\",\n",
    "                          \"n_participants_adult\", \"n_males\", \"n_females\", \"n_killed\"]\n",
    "\n",
    "for column in columns_to_convert_int:\n",
    "    df_incidents[column] = df_incidents[column].astype(int)\n",
    " \n",
    "df_incidents.describe(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand what is the semantic of the text attributes and their frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top notes text motivations\n",
    "df_incidents['notes'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top incident_characteristics1 text motivations\n",
    "df_incidents['incident_characteristics1'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top incident_characteristics2 text motivations\n",
    "df_incidents['incident_characteristics2'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `notes` attribute contains arbitrary values, difficult to extract and categorize, alongside the number of non-NA records for this attribute is very low so it result not useful for the goal of the analysis. \n",
    "\n",
    "The attribute `incident_characteristics1` describe the specificity of the incidents, sometimes relative to the type of shot (_dead, injured, wounded, accidental, suicide, etc_) while the attribute `incident_characteristics2` describe the specificity of the context in which the incident happened or has been recorded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_text_mask = (df_incidents['incident_characteristics1'].notna() & df_incidents['incident_characteristics2'].notna())\n",
    "# Count the number of records that have both attributes not null\n",
    "valid_text_mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of records that have at least a non-Na string is high but due to the string nature of this two fields and the difficult to manipualte them, they are temporarily discarded and used later in the analysis to provide more context (_for example, trying to extract a categorical variable from them_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop\n",
    "df_incidents.drop(['incident_characteristics1', 'incident_characteristics2', 'notes'], axis=1, inplace=True)\n",
    "\n",
    "df_incidents.head()\n",
    "\n",
    "\n",
    "# Maybe drop state and senate district: state_house_district', 'state_senate_district', 'congressional_district'.\n",
    "# Convert them from float to int\n",
    "df_incidents.drop(['address'], axis=1, inplace=True) \n",
    "\n",
    "df_incidents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another text attribute is `participant_age_group1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents['participant_age_group1'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This attribute can be useful to reconstruct the missing values of `n_participants_child`, `n_participants_teen` and `n_participants_adult` so we decide to not drop it. \n",
    "\n",
    "Let's also consider the `date` attribute, defining the range of years that the dataset refer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents['date'] = pd.to_datetime(df_incidents['date'])\n",
    "\n",
    "df_incidents['year'] = df_incidents['date'].dt.year\n",
    "\n",
    "sorted(df_incidents['year'].value_counts().nlargest(20).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assumed that the `date` referring 2028,2029,2030 are errors so the year's range is defined over $[2013,2019]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring dataset errors, there are various type such as: cities located in wrong states, logitude and latiude \n",
    "# wrong years in incident dataframe (incidents in 2029 and 2030, maybe they were 2019-2020 since data is until 2020)\n",
    "\n",
    "# Changing dates in df_incidents\n",
    "\n",
    "df_incidents['date'] = df_incidents['date'].astype(str).str.replace('2028', '2018')\n",
    "df_incidents['date'] = df_incidents['date'].astype(str).str.replace('2029', '2019')\n",
    "df_incidents['date'] = df_incidents['date'].astype(str).str.replace('2030', '2020')\n",
    "\n",
    "df_incidents['date'].str.split('-').str[0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each year, we have a number of records of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_counts = df_incidents['date'].str.split('-').str[0].value_counts()\n",
    "print(year_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot visualizes the distribution of total participants in incidents across different states. This provide insights into the geographic distribution of incidents and help identify states with higher or lower levels of participation, used later in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by state and compute number pf partecipants (per state)\n",
    "participants_per_state = df_incidents.groupby('state')['n_participants'].sum().reset_index()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(participants_per_state['state'], participants_per_state['n_participants'])\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Total number of participants')\n",
    "plt.title('Participants per state')\n",
    "plt.xticks(rotation=90) \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning [#WIP]()\n",
    "- Remove Duplicates\n",
    "- select attributes (to identify the relevant __after looking to correlation matrix__)\n",
    "- reduce the data dimension (refer to number of attributes, allows categorization of other attributes, __(todo in preparation after cleaning)__\n",
    "dropping the useless) \n",
    "    - look at correlation matrix\n",
    "    - feature creation by __filter methods, wrapper, embedded methods__. It may regard the creation of *systematic indicators*, so are domain-specific.\n",
    "- select records --> sampling (random sampling)\n",
    "    - check what are the composition (e.g. 80% adult, 10% teen, 10% kids) __(todo in preparation after cleaning)__\n",
    "- treat missing values\n",
    "    - mean, median, mode to reconstruct\n",
    "    - classification/regression (?)\n",
    "- discretization\n",
    "    - supervised discretization based on entropy (_explain why we do not use discretization)\n",
    "- normalization (?)\n",
    "- treat outliers (_in data cleaning_)\n",
    "- Remove NaNs\n",
    "    - Some records with NaNs can be reconstructed: reconstruct the null value of `partecipant_age1` starting from the value of `participant_age_group1` that can assume 3 string value \"Adult 18+\", \"Teen 12-17\",\"Child 0-11\". (Beforehand we already dropped the NaN records for all attributes except `partecipant_age1`). To reconstruct the exact value, take the `partecipant_age_group1`  and as a value take the mode of all the records in the same group.\n",
    "- PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data cleaning phase, we set a threshold of 50% of NA values for each column and remove the redundand records, if any:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaNs\n",
    "\n",
    "df_incidents.isna().sum()\n",
    "\n",
    "#   Let's get the % of nans with respect to the total number of records, if is > 50% we drop the column\n",
    "\n",
    "for col in df_incidents.columns:\n",
    "    pct_missing = np.mean(df_incidents[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "\n",
    "    # drop if more than 50% of the data is missing\n",
    "    if pct_missing > 0.5:\n",
    "        df_incidents.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "df_incidents_nodup = df_incidents.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, no column have more than 50% of null values so among the columns we have selectd, none of them is actually dropped. It's important to highlight that the attribute with the most value missing is `partecipant_age1` so we will see later if this value can be reconstructed/substitute by exploiting other attributes about age of partecipants. For the moment, let's evaluate distribution and standard deviation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the records with NA value, excluding `partecipant_age1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = ['participant_age1']\n",
    "\n",
    "# Create a new DataFrame with NaNs removed for all columns except 'participant_age1'\n",
    "#df_incidents_nodup = df_incidents_nodup.dropna(subset=[col for col in df_incidents_nodup.columns if col not in columns_to_exclude])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame to avoid modifying the original\n",
    "df_incidents_copy = df_incidents.copy()\n",
    "\n",
    "# Create a dictionary to store the mode values for each 'participant_age_group1'\n",
    "mode_dict = df_incidents_copy.groupby('participant_age_group1')['participant_age1'].apply(lambda x: x.mode().values[0]).to_dict()\n",
    "\n",
    "# Define a function to fill missing values in 'participant_age1' based on 'participant_age_group1'\n",
    "def fill_age_with_mode(row):\n",
    "    if pd.isna(row['participant_age1']):\n",
    "        return mode_dict.get(row['participant_age_group1'], row['participant_age1'])\n",
    "    return row['participant_age1']\n",
    "\n",
    "# Apply the function to create a new column 'filled_age1' with updated values\n",
    "df_incidents_copy['filled_age1'] = df_incidents_copy.apply(fill_age_with_mode, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaNs\n",
    "\n",
    "df_incidents_nodup.isna().sum()\n",
    "\n",
    "#   Let's get the % of nans with respect to the total number of records, if is > 50% we drop the column\n",
    "\n",
    "for col in df_incidents_copy.columns:\n",
    "    pct_missing = np.mean(df_incidents_copy[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "\n",
    "    # drop if more than 50% of the data is missing\n",
    "    if pct_missing > 0.5:\n",
    "        df_incidents_copy.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# Finally deleting all NaNs\n",
    "#df_incidents_nodup = df_incidents_nodup.dropna()\n",
    "\n",
    "# Drop duplicates\n",
    "df_incidents_nodup = df_incidents_copy.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = df_incidents_nodup['participant_age1'].dropna().astype(int)\n",
    "\n",
    "# Create a boxplot to visualize the distribution\n",
    "plt.boxplot(filtered_data, vert=True)  # vert=False makes it horizontal\n",
    "plt.xlabel('Age')\n",
    "plt.title('Boxplot of Participant Age 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = df_incidents_nodup['filled_age1'].dropna().astype(int)\n",
    "\n",
    "# Calculate the mean and standard deviation\n",
    "mean_age = np.mean(filtered_data)\n",
    "std_dev_age = np.std(filtered_data)\n",
    "\n",
    "# Create a histogram to visualize the distribution\n",
    "plt.hist(filtered_data, bins=20, edgecolor='k')  # You can adjust the number of bins as needed\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Participant Age 1')\n",
    "\n",
    "# Add mean and standard deviation to the plot\n",
    "plt.axvline(mean_age, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_age:.2f}')\n",
    "plt.axvline(mean_age + std_dev_age, color='green', linestyle='dashed', linewidth=2, label=f'Std Dev: {std_dev_age:.2f}')\n",
    "plt.axvline(mean_age - std_dev_age, color='green', linestyle='dashed', linewidth=2)\n",
    "\n",
    "plt.legend()  # Add a legend to the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# boxplot of min_age_participants\n",
    "df_incidents.boxplot(column=['min_age_participants'])\n",
    "\n",
    "# Interestingly when you remove some wrong values or outliers you cant get different\n",
    "# plot of other variables eg: this boxplot show clearly that age is 1e11, but if you remove some outlier then you get anomalous values around 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Mass Shooting #toreview\n",
    "\n",
    "As we can see sometimes the number of people killed or injured it's not an incident it's a mass shooting\n",
    "\n",
    "Let's remove this by taking into account this definition, given by FBI:\n",
    "\n",
    "```\n",
    "    The Federal Bureau of Investigation (FBI) defines a mass shooting as an incident in which four or more people, not including the shooter, are killed. This definition is often used in the United States.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#visualize datapoint with more than 20 killed\n",
    "df_incidents_nodup[df_incidents_nodup['n_killed'] > 20]\n",
    "\n",
    "# summing n_males and females killed over a total participants score\n",
    "df_incidents_nodup['n_participants'].sum()/(df_incidents_nodup['n_females'].sum()+df_incidents_nodup['n_males'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing also when `n_participants` is >= 5.\n",
    "This will change the correlation matrix, try to remove this and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize outliers with a boxplot\n",
    "\n",
    "\n",
    "df_incidents_nodup.boxplot(column='n_killed')\n",
    "df_incidents_nodup.boxplot(column='n_injured')\n",
    "\n",
    "# Remove outliers if n_killed or n_injured > 4\n",
    "df_incident_no_outliers = df_incidents_nodup[(df_incidents_nodup['n_killed'] < 4) & (df_incidents_nodup['n_injured'] < 4)]\n",
    "\n",
    "# We have to remove when number of participants is more than 5 also\n",
    "df_incident_no_outliers = df_incident_no_outliers[df_incident_no_outliers['n_participants'] < 5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Outliers removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incident_no_outliers.boxplot(column=['n_killed', 'n_injured'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining outliers check on the dataset\n",
    "\n",
    "We will plot all the boxplot relative to the numerical features and check if there are some outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot different subplots of boxplot for each numerical column\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get the numerical columns of the data frame\n",
    "numerical_columns = df_incident_no_outliers.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# create a boxplot for each numerical column\n",
    "for column in numerical_columns:\n",
    "    plt.figure()\n",
    "    plt.boxplot(df_incident_no_outliers[column])\n",
    "    plt.title(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incident_no_outliers.plot(kind='scatter', x='longitude', y='latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo\n",
    "Analyse the box-plot above respect to the outlier, distribution, standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some insights from outliers plot\n",
    "\n",
    "How about the min, max ages and average? Why so hig? Let's check the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get hist of age min, max and avg\n",
    "\n",
    "df_incident_no_outliers['avg_age_participants'].hist()\n",
    "df_incident_no_outliers['min_age_participants'].hist()\n",
    "df_incident_no_outliers['max_age_participants'].hist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get the numerical max and mins\n",
    "print(\"Absolute minimum age: \", df_incident_no_outliers['min_age_participants'].min())\n",
    "print(\"Absolute maximum age: \", df_incident_no_outliers['max_age_participants'].max())\n",
    "\n",
    "print(\"Minimum of max age: \", df_incident_no_outliers['max_age_participants'].min())\n",
    "print(\"Maximum of max age: \", df_incident_no_outliers['max_age_participants'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Distributions\n",
    "\n",
    "From the first we can see that plotting distirbution of n_killed against the number of incidents we can see that in the majority of the incidents people do not die. \n",
    "\n",
    "We have a distribution skewed to the left so the asimmetry index must be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Killed People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using seaborn to visualize the distribution of n_killed \n",
    "\n",
    "# In %\n",
    "print((df_incident_no_outliers.groupby('n_killed').size()/len(df_incident_no_outliers)*100))\n",
    "\n",
    "df_incident_no_outliers['n_killed'].value_counts().plot(kind='bar')\n",
    "\n",
    "# PIE CHARTs ARE ILLEGAL\n",
    "#df_incident_no_outliers['n_killed'].value_counts().plot(kind='pie')\n",
    "\n",
    "# Asimmetry index is pos\n",
    "skewness_n_killed = df_incident_no_outliers['n_killed'].skew()\n",
    "print('\\n\\n',\"Skewness of n_killed: %f\" % skewness_n_killed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Injured People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In %\n",
    "print((df_incident_no_outliers.groupby('n_injured').size()/len(df_incident_no_outliers)*100))\n",
    "\n",
    "df_incident_no_outliers['n_injured'].value_counts().plot(kind='bar')\n",
    "\n",
    "# Asimmetry index is pos\n",
    "skewness_n_injured = df_incident_no_outliers['n_injured'].skew()\n",
    "print('\\n\\n',\"Skewness of n_injured: %f\" % skewness_n_injured)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Numero totale di morti per ogni stato##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio killed/participants\n",
    "\n",
    "#gravitÃ  media degli incidenti in termini di vittime per partecipante.\n",
    "# Calcola il numero totale di morti per ogni stato\n",
    "# Calcola il numero totale di morti per ogni stato\n",
    "deaths_by_state = df_incident_no_outliers.groupby('state')['n_killed'].sum()\n",
    "\n",
    "#numero totale di partecipanti per stato\n",
    "participants_by_state = df_incident_no_outliers.groupby('state')['n_participants'].sum()\n",
    "\n",
    "#rapporto Morti/Partecipanti per stato\n",
    "mortality_ratio_by_state = deaths_by_state / participants_by_state\n",
    "\n",
    "#creo un nuovo DataFrame per mostrare i risultati\n",
    "mortality_ratio_df = pd.DataFrame({\n",
    "    'Stato': mortality_ratio_by_state.index,\n",
    "    'Rapporto Morti/Partecipanti': mortality_ratio_by_state.values\n",
    "})\n",
    "# stampo l'istogramma\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(mortality_ratio_df['Stato'], mortality_ratio_df['Rapporto Morti/Partecipanti'], color='skyblue')\n",
    "plt.xlabel('Stato')\n",
    "plt.ylabel('Rapporto Morti/Partecipanti')\n",
    "plt.title('Rapporto Morti/Partecipanti per Stato')\n",
    "plt.xticks(rotation=90)  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Correlation analysis\n",
    "Use the correlation coefficients to understand correlation between a set of attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Correlation on injured-killed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation injured and killed\n",
    "corr_nk_ninj = df_incident_no_outliers['n_killed'].corr(df_incident_no_outliers['n_injured'])\n",
    "print(\"Correlation between n_killed and n_injured: \", corr_nk_ninj)\n",
    "\n",
    "# Visualizing ration of n_participants on female and male, usually these are almost the same number.\n",
    "df_incident_no_outliers['n_participants'].sum()/(df_incident_no_outliers['n_females'].sum()+df_incident_no_outliers['n_males'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix of all our features [#WIP]()\n",
    "\n",
    "#### Intresting correlations that can be inferred\n",
    "-  `n_participants` and `n_males` is higly correlated: 0.83 (This will lower if we filter the `n_participants` > 5, still high tough)\n",
    "-  `n_participants` and `n_females` is not: 0.36\n",
    "- After converting some feature from object to int-float intresting correlation arises!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector containig all numerical features\n",
    "numerical_features = df_incident_no_outliers.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "plt.figure(figsize=(20, 16))  # Adjust the values (width, height) as needed\n",
    "correlation_matrix_all = df_incident_no_outliers[numerical_features].corr()\n",
    "sns.heatmap(correlation_matrix_all, annot=True)\n",
    "\n",
    "# As for the correlation n_males & n_participants we can do statistical significance test, in our case the \n",
    "# null hypotesis is that the two variables are independent, we can reject the null hypotesis if the p-value is < 0.05\n",
    "\n",
    "# Contigency table is used for categorical variable, so we can do a thing like this, take intervals 0-1 and 2-3 of participants\n",
    "# and make this a categorical variable, then we can do a chi-square test\n",
    "\n",
    "# adding low_participants column and high_participants column\n",
    "# need to understand if this make sense or it's redundant.\n",
    "df_incident_no_outliers['low_participants'] = df_incident_no_outliers['n_participants'].apply(lambda x: 1 if x < 2 else 0)\n",
    "df_incident_no_outliers['high_participants'] = df_incident_no_outliers['n_participants'].apply(lambda x: 1 if x > 1 else 0)\n",
    "\n",
    "# And now a little visualization of the chi2 test\n",
    "# Visualize the result of the test\n",
    "# print max vaues of n_participants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results of $\\chi^2$ test\n",
    "\n",
    "Wrote a little function that emulates how R show result of a statistical test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# get contingency table\n",
    "contingency_table = pd.crosstab(df_incident_no_outliers['n_males'], df_incident_no_outliers['n_participants'])\n",
    "\n",
    "# perform chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table.values)\n",
    "\n",
    "# Visualize the result of the test\n",
    "# print max vaues of n_participants\n",
    "\n",
    "# Heatmap of expected against observed frequencies\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 6), sharey=True)\n",
    "\n",
    "sns.heatmap(expected, annot=True, fmt='.2f', cmap='Blues', ax=ax1)\n",
    "sns.heatmap(contingency_table, annot=True, fmt='d', cmap='Reds', ax=ax2)\n",
    "\n",
    "ax1.set_xlabel('n_participants')\n",
    "ax1.set_ylabel('n_males')\n",
    "ax1.set_title('Expected Frequencies')\n",
    "\n",
    "ax2.set_xlabel('n_participants')\n",
    "ax2.set_title('Observed Frequencies')\n",
    "\n",
    "plt.suptitle('Contingency Table with Expected Frequencies (Blue) and Observed Frequencies (Red)', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_chi2_results(chi2, p, dof, expected):\n",
    "    print(\"Chi-squared test results:\")\n",
    "    print(f\"  Chi-squared = {chi2:.20f}\")\n",
    "    print(f\"  Degrees of freedom = {dof}\")\n",
    "    print(f\"  p-value = {p:.20f}\")\n",
    "    print(\"  Expected frequencies:\")\n",
    "    for i in range(expected.shape[0]):\n",
    "        for j in range(expected.shape[1]):\n",
    "            print(f\"    {contingency_table.index[i]} vs {contingency_table.columns[j]}: {expected[i][j]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Chi2 #WIP\n",
    "print_chi2_results(chi2, p, dof, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age and Sex distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of incident of with males and femals plots\n",
    "\n",
    "# Males incidents\n",
    "df_incident_no_outliers['n_males'].value_counts().plot(kind='bar')\n",
    "\n",
    "# Females incidents\n",
    "df_incident_no_outliers['n_females'].value_counts().plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "# Plot the male incidents in the first subplot\n",
    "df_incident_no_outliers['n_males'].value_counts().plot(kind='bar', ax=ax1)\n",
    "ax1.set_xlabel('Number of Males')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Male Victims in Gun Incidents')\n",
    "\n",
    "# Plot the female incidents in the second subplot\n",
    "df_incident_no_outliers['n_females'].value_counts().plot(kind='bar', ax=ax2)\n",
    "ax2.set_xlabel('Number of Females')\n",
    "# Numer of incidents with particular numb of female and male\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Distribution of Female Victims in Gun Incidents')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of death in each state \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#usa_map = gpd.read_file('../map_data/usa-states-census-2014.shp')\n",
    "\n",
    "# use entire world map\n",
    "usa_map = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "# show map\n",
    "\n",
    "\n",
    "\n",
    "usa_map.plot(figsize=(30,40))\n",
    "\n",
    "# Draw red point for each latitude and longitude on df_incidents for 50 sampled incidents\n",
    "\n",
    "sample_incidents = df_incidents_nodup.sample(len(df_incidents_nodup)//100)\n",
    "\n",
    "for index, row in sample_incidents.iterrows():\n",
    "    plt.plot(row['longitude'], row['latitude'], 'ro')\n",
    "    \n",
    "\n",
    "usa_map.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(df_incidents_nodup['state'].unique())\n",
    "# We have 49 states in the data but there are 50, we lack Alaska and Hawaii american states why?\n",
    "\n",
    "df_incidents_nodup['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to plot a colormap or heatmap \n",
    "\n",
    "state_incidents = {}\n",
    "\n",
    "usa_incidents_map = gpd.read_file('../map_data/usa-states-census-2014.shp')\n",
    "\n",
    "# Counting the number of incidents per state\n",
    "for state in sample_incidents['state'].unique():\n",
    "    state_incidents[state] = len(sample_incidents[sample_incidents['state'] == state])\n",
    "\n",
    "\n",
    "max_incidents = max(state_incidents.values())\n",
    "min_incidents = min(state_incidents.values())\n",
    "\n",
    "for state in state_incidents:\n",
    "    state_incidents[state] = (state_incidents[state] - min_incidents) / (max_incidents - min_incidents)\n",
    "    \n",
    "# Convert in dataframe and divide key and value in two columns state and score\n",
    "state_incidents_df = pd.DataFrame.from_dict(state_incidents, orient='index')\n",
    "state_incidents_df.reset_index(inplace=True)\n",
    "state_incidents_df.columns = ['state', 'score']\n",
    "\n",
    "\n",
    "# histogram of the scores\n",
    "# why 46? explore this\n",
    "print(len(state_incidents_df['state'].unique()))\n",
    "state_incidents_df['score'].plot(kind='hist', bins=len(state_incidents_df['state'].unique()))\n",
    "\n",
    "\n",
    "# To get a color map we need to merge the map geometric data dataframe with state column (need to find or build it) with our dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is from sampled data, be careful! [#WIP]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_incidents['city_or_county'].groupby(sample_incidents['state']).value_counts().plot(kind='bar')\n",
    "sample_incidents['state'].value_counts().plot(kind='bar')\n",
    "# omit x axis name\n",
    "plt.xticks([])\n",
    "\n",
    "state_incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum arrested, injured, killed and compare to n_participants to a random record\n",
    "sample_incidents['n_participants'] == sample_incidents['n_arrested'] + sample_incidents['n_injured'] + sample_incidents['n_killed']\n",
    "\n",
    "\n",
    "#sample_incidents['n_participants'][88251] == sample_incidents['n_arrested'][88251] + sample_incidents['n_injured'][88251] + sample_incidents['n_killed'][88251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../source/ds/incidents_taskDU.csv'\n",
    "df_incident_no_outliers.to_csv(file_path, index=False)\n",
    "\n",
    "print(f'Data saved to {file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
